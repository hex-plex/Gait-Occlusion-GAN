{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python395jvsc74a57bd003dd13d48678367c8c9c8d2bc4e4058efaffff37d2a70d9886c86b6aa2328a71",
   "display_name": "Python 3.9.5 64-bit ('myenv': conda)"
  },
  "metadata": {
   "interpreter": {
    "hash": "03dd13d48678367c8c9c8d2bc4e4058efaffff37d2a70d9886c86b6aa2328a71"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import *\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from gait import *\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "from utils import angle_ims, get_device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 124/124 [00:00<00:00, 493.04it/s]\n"
     ]
    }
   ],
   "source": [
    "os.chdir('/home/ishikaa/Downloads/')\n",
    "labels = fetch_labels(label_angle='000',save=False,override=True)\n",
    "files = [filename for filename, value in labels.items() if value==4]\n",
    "images_0_4 = [preprocess(cv2.imread(file))/255 for file in files]\n",
    "y = np.mean([image for image in images_0_4],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv3D(nn.Module):\n",
    "\n",
    "    '''\n",
    "    Performs 3D convolution\n",
    "    '''\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        super(Conv3D, self).__init__()\n",
    "        self.conv1 = self._convblock(1,16,3,1,False)\n",
    "        self.conv2 = self._convblock(16,32,1,1,False)\n",
    "        self.conv3 = self._convblock(32,16,1,1,False)\n",
    "        self.conv4 = self._convblock(16,1,1,1,True)\n",
    "\n",
    "    def _convblock(self,in_channels,out_channels,ksized,ksize,last):\n",
    "        '''\n",
    "        Makes a block of layers (Conv3d,ReLU,Maxpool3d,BatchNorm3d(only if !last))\n",
    "        '''\n",
    "\n",
    "        l1 = nn.Conv3d(in_channels=in_channels,out_channels=out_channels,kernel_size=(ksized,ksize,ksize))\n",
    "        l2 = nn.ReLU()\n",
    "        \n",
    "        if last:\n",
    "            return nn.Sequential(l1,l2)\n",
    "        else:\n",
    "            l3 = nn.MaxPool3d((1, 1, 1))\n",
    "            l4 = nn.BatchNorm3d(out_channels)\n",
    "            return nn.Sequential(l1,l2,l3,l4)\n",
    "        \n",
    "        \n",
    "    def forward(self,x):\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.conv2(out)\n",
    "        out = self.conv3(out)\n",
    "        out = self.conv4(out)\n",
    "        \n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Conv3D()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "cuda:0\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Conv3D(\n",
       "  (conv1): Sequential(\n",
       "    (0): Conv3d(1, 16, kernel_size=(3, 1, 1), stride=(1, 1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool3d(kernel_size=(1, 1, 1), stride=(1, 1, 1), padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (conv2): Sequential(\n",
       "    (0): Conv3d(16, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool3d(kernel_size=(1, 1, 1), stride=(1, 1, 1), padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (conv3): Sequential(\n",
       "    (0): Conv3d(32, 16, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool3d(kernel_size=(1, 1, 1), stride=(1, 1, 1), padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (conv4): Sequential(\n",
       "    (0): Conv3d(16, 1, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "    (1): ReLU()\n",
       "  )\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "model = Conv3D()\n",
    "device = get_device()\n",
    "print(device)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PEIData(Dataset):\n",
    "\n",
    "    def __init__(self, num_exps,transform=None):\n",
    "        \"\"\"\n",
    "        Custom dataset for images of a certain keypose at a given angle.\n",
    "\n",
    "        Args:\n",
    "            angle (int)     : Angle\n",
    "            keypose (int)   : Key-pose/Cluster\n",
    "            data_path (str) : Path where dataset is downloaded\n",
    "        \"\"\"\n",
    "        \n",
    "        ds = []\n",
    "        for i in range(num_exps):\n",
    "            exp = angle_ims(exp=i+1,angle=0,keypose = 4)\n",
    "            ds = ds + exp\n",
    "\n",
    "        images = np.empty((len(ds),3,ds[0].shape[2]//2,ds[0].shape[1]//2))\n",
    "\n",
    "        for i in range(len(ds)):\n",
    "            images[i] = np.asarray([preprocess(im)/255 for im in ds[i]])\n",
    "        \n",
    "        self.images = images.reshape(images.shape[0],1,images.shape[1],images.shape[2],images.shape[3]).astype('float32')\n",
    "\n",
    "        #Avg PEI after PCA .\n",
    "        # self.y = np.mean([image for image in images_0_4],axis=0)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.images[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = PEIData(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "len(exp1)+len(exp2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = []\n",
    "for i in range(1,3):\n",
    "    exp,_ = angle_ims(exp=i,angle=0,keypose = 4)\n",
    "    total = total + exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(240, 320, 3)"
      ]
     },
     "metadata": {},
     "execution_count": 47
    }
   ],
   "source": [
    "total[0][0].shape"
   ]
  },
  {
   "source": [
    "## Training"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = DataLoader(data, 1, False)\n",
    "#Loss\n",
    "criterion = nn.MSELoss()\n",
    "#Optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "batch = 8\n",
    "mean_frame = torch.from_numpy(mean_frame).to(device,dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "metadata": {},
     "execution_count": 80
    }
   ],
   "source": [
    "data[0].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch: 1 \tTraining Loss: 0.272077\nEpoch: 2 \tTraining Loss: 0.272077\nEpoch: 3 \tTraining Loss: 0.272077\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 3\n",
    "\n",
    "for epoch in range(1, n_epochs+1):\n",
    "    # monitor training loss\n",
    "    train_loss = 0.0\n",
    "\n",
    "    #Training\n",
    "    for data in dl:\n",
    "        images = data\n",
    "        images = images.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(images)\n",
    "        temp_out = torch.reshape(out, (out.shape[3],out.shape[4]))\n",
    "        # print('Outputs: ',temp_out.dtype,' Targets shape: ',mean_frame.dtype)\n",
    "        loss = criterion(temp_out, mean_frame)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()*images.size(0)\n",
    "          \n",
    "    train_loss = train_loss/len(dl)\n",
    "    print('Epoch: {} \\tTraining Loss: {:.6f}'.format(epoch, train_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([1, 160, 120])"
      ]
     },
     "metadata": {},
     "execution_count": 66
    }
   ],
   "source": [
    "dataiter = iter(test_dl)\n",
    "images = dataiter.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 1, 160, 120])"
      ]
     },
     "metadata": {},
     "execution_count": 61
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(1, 1, 160)"
      ]
     },
     "metadata": {},
     "execution_count": 63
    }
   ],
   "source": [
    "(out.shape[0],out.shape[2],out.shape[3])"
   ]
  },
  {
   "source": [
    "## USE FOR Y"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "/home/ishikaa/Desktop/Repos/Gait-Occlusion-GAN\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('',mean_frame)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "source": [
    "## Encoder testings\n",
    "input:  `<class 'torch.Tensor'> torch.Size([m, 1, 160, 120])`"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from encoder import Autoencoder"
   ]
  }
 ]
}